---
title: "Extraccion de terminos TFM"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


Leemos los documentos.
```{r echo=FALSE}
library(readtext)

hilos = 8

#font_import()

#Ruta de trabajo
setwd("~/TFM")

ruta = "/doc"
#ruta = "/Users/pedrohv/TFM/TerminologíasInteractivas/data/covid19/raw/documents"

#Leer un corpus
docs <- readtext(paste0(getwd(),ruta, "*"), #Leo todo lo que tenga ese path
                 #docvarsfrom = "filenames", 
                 #docvarnames = c("document", "language"),
                 #dvsep = "_", 
                 encoding = "UTF-8-BOM", #"ISO-8859-1", #Casi mejor no pongo nada porque no sÃ© el encoding
                 verbosity = 3) 

print("Se han leido los documentos del corpus con éxito")

```


Creamos el corpus de quanteda
```{r}
library(quanteda)

# create quanteda corpus
quanteda_options(threads = hilos)
quancorpusDocs <- corpus(docs)

#Obtenemos un resumen del corpus que hemops creado
summ <- summary(quancorpusDocs,    #Esto tarda unos segundos. Types es el num de tokens Únicos.
                n = nrow(docs))    #Por defecto son 100
sum(summ$Sentences)
sum(summ$Tokens)

#Puedo sacar los textos 
tDocs <- texts(quancorpusDocs) #No tarda nada. 
                       #Un vector nombrado (cada elemento tiene el nombre del doc). 
                       #Cada elemento es una cadena con el texto del doc.
```


Descargamos el modelo udpipe de Google y extraemos los terminos.
```{r}
library(udpipe)
library(tictoc)

model <- udpipe_download_model(language = "spanish")
#udmodel_spanish_gsd <- udpipe_load_model(file = 'spanish-gsd-ud-2.4-190531.udpipe')

path <- model$file_model

tic()
x <- udpipe(tDocs, path, parallel.cores = hilos)
toc()

saveRDS(x, file = "termExtraction/udpipeEspañol1.rds")
#x <- readRDS(file = "airbus.rds")
```



```{r}
library(lattice)

#Plotting Part-of-speech tags from the given text

stats <- txt_freq(x$upos) #upos = universal part of speech
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = stats, col = "yellow", 
         main = "UPOS (Universal Parts of Speech)\n frequency of occurrence", 
         xlab = "Freq")
```



```{r}
stats <- subset(x, upos %in% "NOUN")
stats <- txt_freq(x = stats$lemma)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 30), col = "cadetblue", main = "Most occurring nouns", xlab = "Freq")
```



```{r}
stats <- subset(x, upos %in% c("VERB")) 
stats <- txt_freq(stats$token)# tambiÃ©n puedo poner lemma si quiero ver el verbo en infinitivo
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 20), col = "gold", 
         main = "Most occurring Verbs", xlab = "Freq")
```



```{r}
stats <- subset(x, upos %in% c("VERB")) 
stats <- txt_freq(stats$lemma)# el lemma para el verbo en infinitivo
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 20), col = "gold", 
         main = "Most occurring Verbs (lemma)", xlab = "Freq")
```



```{r}
## Collocation (words following one another)
stats <- keywords_collocation(x = x, 
                             term = "token", group = c("doc_id", "paragraph_id", "sentence_id"),
                             ngram_max = 4)
## Co-occurrences: How frequent do words occur in the same sentence, in this case only nouns or adjectives
stats <- cooccurrence(x = subset(x, upos %in% c("NOUN", "ADJ")), 
                     term = "lemma", group = c("doc_id", "paragraph_id", "sentence_id"))
## Co-occurrences: How frequent do words follow one another
stats <- cooccurrence(x = x$lemma, 
                     relevant = x$upos %in% c("NOUN", "ADJ"))
## Co-occurrences: How frequent do words follow one another even if we would skip 2 words in between
stats <- cooccurrence(x = x$lemma, 
                     relevant = x$upos %in% c("NOUN", "ADJ"), skipgram = 2)
head(stats)
```



```{r}
# library(igraph)
# library(ggraph)
# library(ggplot2)
# library(extrafont)
#
# wordnetwork <- head(stats, 30)
# wordnetwork <- graph_from_data_frame(wordnetwork)
# ggraph(wordnetwork, layout = "fr") +
#   geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "pink") +
#   geom_node_text(aes(label = name), col = "darkgreen", size = 4) +
#   theme_graph(base_family = "Arial Narrow") +
#   theme(legend.position = "none") +
#   labs(title = "Cooccurrences within 3 words distance", subtitle = "Nouns & Adjective")
```



```{r warning=FALSE}
library(textrank)
stats <- textrank_keywords(x$lemma,
                          relevant = x$upos %in% c("NOUN", "ADJ"),
                          ngram_max = 8, sep = " ")
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
library(wordcloud)
suppressWarnings(wordcloud(words = stats$keyword, freq = stats$freq))
```

```{r}
TermFreq <- document_term_frequencies(x)
```



```{r}
stats <- keywords_rake(x = x, 
                       term = "lemma", 
                       group = "doc_id", 
                       relevant = x$upos %in% c("NOUN", "ADJ"))
stats$key <- factor(stats$keyword, levels = rev(stats$keyword))
stats
```


```{r}
barchart(key ~ rake, 
         data = head(subset(stats, freq > 20), 60), 
         col = "red", 
         main = "Keywords identified by RAKE", 
         xlab = "Rake")
```


Esta figura muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}

tab <- table(x$upos)
tab_ord <- sort(tab, decreasing = T)

barplot(cumsum(tab_ord)/nrow(x),  
        #log="y", #Log scale in y axis
        main="UPOS patterns (Cumulative Sum)",
        ylab="Percentage covered",
        xlab="POS patterns",
        las=2 #Rotated lables in the x axis
      )
```

Esta figura (mucho más mona) muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}
library(ggplot2)
tabsum <- cumsum(tab_ord)/nrow(x)
cumdf <- data.frame(cum = tabsum, 
                    stringsAsFactors = FALSE) #Tiene una única col
cumdf$pat <- rownames(cumdf) #Nueva col con pattens
top <- 12
defcolor <- "#EEEEEE"  #light gray para imprimir (casi no se ve en pantalla). Si uso #BBBBBB sale muy oscuro impreso
             #Un tono más oscuro es #CCCCCC . Si uso #777777 sale oscurito en pantalla pero muy oscuro impreso 
micolor <- c(rep("#CCCCCC", top), rep(defcolor, nrow(cumdf) - top)) #Vector de colores

sumtop <- cumdf$cum[top] #Suma de los 12 primeros
ggplot(data=cumdf, 
       aes(x=pat, y=cum, fill = pat)) +
  scale_x_discrete(limits = cumdf$pat) + #Sin esto ordena alfabéticamente
  scale_y_continuous(labels = scales::percent_format(accuracy = 1),  #Que ponga porcentaje (en lugar de float) en eje y
                     breaks = seq(0,1,0.1), #Que pinte estos (de 0 a 1 (100%) de 0.1 (10%) en 10%)
                     expand = expand_scale(mult = c(0, 0)) #Elimina espacios extra por debajo y por arriba, para que vaya justo de 0 a 1 (100%). 
                    ) +
  labs( #title = "The title",
        #subtitle = "the subtitle",        #will be displayed below the title.
        #caption = "Some ref of copyright" #The text for the caption which will be displayed in the bottom-right of the plot by default.
        #tag = "some letter useful "
        x = "UPOS patterns ordered (most used in the left)", #Label of the x axis
        y = "Percentage of entities covered (cummulative)" #Label of the x axis
      ) +
  geom_bar(stat="identity", 
           show.legend = FALSE, #Avoids leyend (big, one class per color) 
           #color = "#111111", #Color del borde. Si no lo pongo no poner borde
           #fill = defcolor   #Color del relleno
           ) +
  scale_fill_manual (values = micolor, #coloreo distinto EL INTERIOR de las top barras 
                     limits = cumdf$pat #Es imprescindible si estoy forzando el orden
                    ) +
  geom_segment(aes(x=cumdf$pat[1],  y=sumtop  , xend=cumdf$pat[top], yend=sumtop),   #Add a horizontal segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  geom_segment(aes(x=cumdf$pat[top], y=0.0,      xend=cumdf$pat[top], yend=sumtop),   #Add a vertical segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  annotate(geom="text", 
           x=cumdf$pat[1], 
           y=sumtop + 0.05, #A litte above the line
           hjust = 0, #La posición será la del inicio de la cadena 
           label=paste0("The ", top, " most used UPOS cover ", 
                       round(100* max(cumsum(tab_ord[1:top])/nrow(x)), #Top x cumsum
                             digits=0 #Sin decimales
                            ),
                       "% of the terms"
                       ),
           color="red") +
  theme_classic() + #Light es un theme algo más mono que bw o classic pero que impreso no queda bien
  theme(#element_text(size=20),                            #El tamaño del font general
        axis.text.x = element_text(angle = 90,#Para girar las labels del eje x
                                   #size = rel(0.95), # puedo poner un vaor absoluto (e.g. 10) o relativo
                                   vjust = 0.5, #0 means left-justified, 1 means right-justified.
                                   hjust = 1    #0 means left-justified, 1 means right-justified.
                                  ) 
       ) 
```

Tranformacion de UPOS a POS
```{r}
upos <- c("NOUN","ADP","DET","PUNCT","ADJ","PROPN","VERB","NUM","CCONJ","PRON","SCONJ","ADV","AUX","X","SYM","PART","INTJ")
upos
as_phrasemachine(upos)
```

Patron con UPOS
```{r}
statsUPOS <- keywords_phrases(x = x$upos, 
                          term = tolower(x$token), 
                          #pattern = "(DET|NOUN|ADJ)|(PROPN|NOU|NADJ|AUX)",
                          pattern = "((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON)(ADP+DET*((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON))*", #SNP for UPOS
                          is_regex = TRUE, 
                          detailed = FALSE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE.
                         )

#((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON)(ADP+DET*((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON))*
statsUPOS
```

Patron con UPOS
```{r}
statsUPOS <- keywords_phrases(x = x$upos, 
                          term = tolower(x$token), 
                          #pattern = "(DET|NOUN|ADJ)|(PROPN|NOU|NADJ|AUX)",
                          pattern = "(NOUN|PROPN|PRON)((ADJ|NUM)|(NOUN|PROPN|PRON))*((ADP)(DET)*(NOUN|PROPN|PRON)((ADJ|NUM)|(NOUN|PROPN|PRON))*)* ", #SNP for UPOS
                          is_regex = TRUE, 
                          detailed = FALSE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE.
                         )

statsUPOS
```




Esta figura muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}

tabUPOS <- table(statsUPOS$pattern)
tab_ordUPOS <- sort(tabUPOS, decreasing = T)

barplot(cumsum(tab_ordUPOS)/nrow(statsUPOS),  
        #log="y", #Log scale in y axis
        main="UPOS patterns (Cumulative Sum)",
        ylab="Percentage covered",
        xlab="POS patterns",
        las=2 #Rotated lables in the x axis
      )
```

Esta figura (mucho más mona) muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}
library(ggplot2)
tabsum <- cumsum(tab_ordUPOS)/nrow(statsUPOS)
cumdf <- data.frame(cum = tabsum, 
                    stringsAsFactors = FALSE) #Tiene una única col
cumdf$pat <- rownames(cumdf) #Nueva col con pattens
top <- 12
defcolor <- "#EEEEEE"  #light gray para imprimir (casi no se ve en pantalla). Si uso #BBBBBB sale muy oscuro impreso
             #Un tono más oscuro es #CCCCCC . Si uso #777777 sale oscurito en pantalla pero muy oscuro impreso 
micolor <- c(rep("#CCCCCC", top), rep(defcolor, nrow(cumdf) - top)) #Vector de colores

sumtop <- cumdf$cum[top] #Suma de los 12 primeros
ggplot(data=cumdf, 
       aes(x=pat, y=cum, fill = pat)) +
  scale_x_discrete(limits = cumdf$pat) + #Sin esto ordena alfabéticamente
  scale_y_continuous(labels = scales::percent_format(accuracy = 1),  #Que ponga porcentaje (en lugar de float) en eje y
                     breaks = seq(0,1,0.1), #Que pinte estos (de 0 a 1 (100%) de 0.1 (10%) en 10%)
                     expand = expand_scale(mult = c(0, 0)) #Elimina espacios extra por debajo y por arriba, para que vaya justo de 0 a 1 (100%). 
                    ) +
  labs( #title = "The title",
        #subtitle = "the subtitle",        #will be displayed below the title.
        #caption = "Some ref of copyright" #The text for the caption which will be displayed in the bottom-right of the plot by default.
        #tag = "some letter useful "
        x = "UPOS patterns ordered (most used in the left)", #Label of the x axis
        y = "Percentage of entities covered (cummulative)" #Label of the x axis
      ) +
  geom_bar(stat="identity", 
           show.legend = FALSE, #Avoids leyend (big, one class per color) 
           #color = "#111111", #Color del borde. Si no lo pongo no poner borde
           #fill = defcolor   #Color del relleno
           ) +
  scale_fill_manual (values = micolor, #coloreo distinto EL INTERIOR de las top barras 
                     limits = cumdf$pat #Es imprescindible si estoy forzando el orden
                    ) +
  geom_segment(aes(x=cumdf$pat[1],  y=sumtop  , xend=cumdf$pat[top], yend=sumtop),   #Add a horizontal segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  geom_segment(aes(x=cumdf$pat[top], y=0.0,      xend=cumdf$pat[top], yend=sumtop),   #Add a vertical segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  annotate(geom="text", 
           x=cumdf$pat[1], 
           y=sumtop + 0.05, #A litte above the line
           hjust = 0, #La posición será la del inicio de la cadena 
           label=paste0("The ", top, " most used UPOS patterns cover ", 
                       round(100* max(cumsum(tab_ordUPOS[1:top])/nrow(statsUPOS)), #Top x cumsum
                             digits=0 #Sin decimales
                            ),
                       "% of the terms"
                       ),
           color="red") +
  theme_classic() + #Light es un theme algo más mono que bw o classic pero que impreso no queda bien
  theme(#element_text(size=20),                            #El tamaño del font general
        axis.text.x = element_text(angle = 90,#Para girar las labels del eje x
                                   #size = rel(0.95), # puedo poner un vaor absoluto (e.g. 10) o relativo
                                   vjust = 0.5, #0 means left-justified, 1 means right-justified.
                                   hjust = 1    #0 means left-justified, 1 means right-justified.
                                  ) 
       ) 
```

```{r}
library(dplyr)
library(plyr)

#Así, podemos obtener la frecuencia de aparicion de un termino específico
frequencyOfUPOS <- ddply(statsUPOS, .(pattern, ngram), nrow)

frequencyOfUPOS <- frequencyOfUPOS[order(-frequencyOfUPOS$V1),]

#Así, podemos obtener la frecuencia de aparicion de un termino específico
frequencyOfUPOS
```



Patron con UPOS empleando los 12 patrones mas comunes
```{r}
statsUPOScommon <- keywords_phrases(x = x$upos, 
                          term = tolower(x$token), 
                          pattern = "NOUN|PROPN|PRON|NOUNADPDETNOUN|PROPNPROPN|ADJNOUN|NUMNOUN|PROPNPROPNPROPN|PROPNPROPNPROPNPROPN|NOUNPRON|NUMPROPN|NOUNPROPN",
                          #pattern = "((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON)(ADP+DET*((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON))*", #SNP for UPOS
                          is_regex = TRUE, 
                          detailed = TRUE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE.
                         )

#((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON)(ADP+DET*((ADJ|NUM)|(NOUN|PROPN|PRON))*(NOUN|PROPN|PRON))*
```


Esta figura muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}

tabUPOS <- table(statsUPOScommon$pattern)
tab_ordUPOS <- sort(tabUPOS, decreasing = T)

barplot(cumsum(tab_ordUPOS)/nrow(statsUPOS),  
        #log="y", #Log scale in y axis
        main="UPOS patterns (Cumulative Sum)",
        ylab="Percentage covered",
        xlab="POS patterns",
        las=2 #Rotated lables in the x axis
      )
```

Esta figura (mucho más mona) muestra porcentaje acumulado:
```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}
library(ggplot2)
tabsum <- cumsum(tab_ordUPOS)/nrow(statsUPOS)
cumdf <- data.frame(cum = tabsum, 
                    stringsAsFactors = FALSE) #Tiene una única col
cumdf$pat <- rownames(cumdf) #Nueva col con pattens
top <- 12
defcolor <- "#EEEEEE"  #light gray para imprimir (casi no se ve en pantalla). Si uso #BBBBBB sale muy oscuro impreso
             #Un tono más oscuro es #CCCCCC . Si uso #777777 sale oscurito en pantalla pero muy oscuro impreso 
micolor <- c(rep("#CCCCCC", top), rep(defcolor, nrow(cumdf) - top)) #Vector de colores

sumtop <- cumdf$cum[top] #Suma de los 12 primeros
ggplot(data=cumdf, 
       aes(x=pat, y=cum, fill = pat)) +
  scale_x_discrete(limits = cumdf$pat) + #Sin esto ordena alfabéticamente
  scale_y_continuous(labels = scales::percent_format(accuracy = 1),  #Que ponga porcentaje (en lugar de float) en eje y
                     breaks = seq(0,1,0.1), #Que pinte estos (de 0 a 1 (100%) de 0.1 (10%) en 10%)
                     expand = expand_scale(mult = c(0, 0)) #Elimina espacios extra por debajo y por arriba, para que vaya justo de 0 a 1 (100%). 
                    ) +
  labs( #title = "The title",
        #subtitle = "the subtitle",        #will be displayed below the title.
        #caption = "Some ref of copyright" #The text for the caption which will be displayed in the bottom-right of the plot by default.
        #tag = "some letter useful "
        x = "UPOS patterns ordered (most used in the left)", #Label of the x axis
        y = "Percentage of entities covered (cummulative)" #Label of the x axis
      ) +
  geom_bar(stat="identity", 
           show.legend = FALSE, #Avoids leyend (big, one class per color) 
           #color = "#111111", #Color del borde. Si no lo pongo no poner borde
           #fill = defcolor   #Color del relleno
           ) +
  scale_fill_manual (values = micolor, #coloreo distinto EL INTERIOR de las top barras 
                     limits = cumdf$pat #Es imprescindible si estoy forzando el orden
                    ) +
  geom_segment(aes(x=cumdf$pat[1],  y=sumtop  , xend=cumdf$pat[top], yend=sumtop),   #Add a horizontal segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  geom_segment(aes(x=cumdf$pat[top], y=0.0,      xend=cumdf$pat[top], yend=sumtop),   #Add a vertical segment (line)
               size = 0.5, #Grosor de la línea. Por def = 1
               color="red") +
  annotate(geom="text", 
           x=cumdf$pat[1], 
           y=sumtop + 0.05, #A litte above the line
           hjust = 0, #La posición será la del inicio de la cadena 
           label=paste0("The ", top, " most used UPOS patterns cover ", 
                       round(100* max(cumsum(tab_ordUPOS[1:top])/nrow(statsUPOS)), #Top x cumsum
                             digits=0 #Sin decimales
                            ),
                       "% of the terms"
                       ),
           color="red") +
  theme_classic() + #Light es un theme algo más mono que bw o classic pero que impreso no queda bien
  theme(#element_text(size=20),                            #El tamaño del font general
        axis.text.x = element_text(angle = 90,#Para girar las labels del eje x
                                   #size = rel(0.95), # puedo poner un vaor absoluto (e.g. 10) o relativo
                                   vjust = 0.5, #0 means left-justified, 1 means right-justified.
                                   hjust = 1    #0 means left-justified, 1 means right-justified.
                                  ) 
       ) 
```

```{r}
library(dplyr)
library(plyr)

#Así, podemos obtener la frecuencia de aparicion de un termino específico
frequencyOfUPOScommon <- ddply(statsUPOScommon, .(pattern, ngram), nrow)

frequencyOfUPOScommon  <- frequencyOfUPOScommon[order(-frequencyOfUPOScommon$V1),]

#Así, podemos obtener la frecuencia de aparicion de un termino específico
frequencyOfUPOScommon
```


Patrón 1 con POS pattern
```{r}
x$phrase_tag <- as_phrasemachine(x$upos, 
                                 type = "upos" #Puede ser tambiÃ©n "penn-treebank"
                                )#Convierte los tags de upos a phrasemachine (Handler 2016). 

statsPOS <- keywords_phrases(x = x$phrase_tag, 
                          term = tolower(x$token), 
                          pattern = "N(A|N)*(PD*N(A|N)*)*",
                          is_regex = TRUE,
                          detailed = FALSE 
                          )
statsPOS
```



```{r}
x$phrase_tag <- as_phrasemachine(x$upos, 
                                 type = "upos" #Puede ser tambiÃ©n "penn-treebank"
                                )#Convierte los tags de upos a phrasemachine (Handler 2016). 

statsPOS <- keywords_phrases(x = x$phrase_tag, 
                          term = tolower(x$token), 
                          pattern = "(A|N)*N(P+D*(A|N)*N)*", #Default simple noun phrase. See manual.
                          #pattern = "((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)", #From manual. Noun phrase with coordination conjuction. Este patrón es capaz de extraer ligeramente mas cantidad de terminos, pero tambien tarda una cantidad de tiempo mayor.
                          #See also this package to know who/why and how is a full noun phrase.
                          #MÃ¡s abajo estÃ¡n los ejemplos del manual pdf de esta funciÃ³n.
                          #AquÃ� se explica el pattern: (1) http://brenocon.com/oconnor_textasdata2016.pdf (slides informales)
                          #                            (2) https://www.aclweb.org/anthology/W16-5615.pdf  (paper duro y fullNP grammar en el apÃ©ndice del paper) 
                          is_regex = TRUE, 
                          #ngram_max. Por defecto es 8. It is an integer indicating to allow phrases to be found up to ngram maximum number of terms following each other. Only used if is_regex is set to TRUE.
                          #sep = " ". Character indicating how to collapse the phrase of terms which are found. Defaults to using a space.
                          detailed = FALSE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE.
                                          #With TRUE you get keyword, ngran, pattern, start, end
                                          #With FALSE you get keyword, ngram, freq, key
                         )
statsPOS
```


```{r echo=FALSE, fig.width=8, fig.height=5, fig.align='center'}

tabPOS <- table(statsPOS$pattern)
tab_ordPOS <- sort(tabPOS, decreasing = T)

barplot(cumsum(tab_ordPOS)/nrow(statsPOS),  
        #log="y", #Log scale in y axis
        main="sPOS patterns (Cumulative Sum)",
        ylab="Percentage covered",
        xlab="POS patterns",
        las=2 #Rotated lables in the x axis
      )
```


Patrón 2 con POS pattern
```{r}
x$phrase_tag <- as_phrasemachine(x$upos, 
                                 type = "upos" #Puede ser tambiÃ©n "penn-treebank"
                                )#Convierte los tags de upos a phrasemachine (Handler 2016). 

stats3  <- keywords_phrases(x = x$phrase_tag, 
                          term = tolower(x$token), 
                          #pattern = "(A|N)*N(P+D*(A|N)*N)*", #Default simple noun phrase. See manual.
                          pattern = "((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)", #From manual. Noun phrase with coordination conjuction
                          #See also this package to know who/why and how is a full noun phrase.
                          #MÃ¡s abajo estÃ¡n los ejemplos del manual pdf de esta funciÃ³n.
                          #AquÃ� se explica el pattern: (1) http://brenocon.com/oconnor_textasdata2016.pdf (slides informales)
                          #                            (2) https://www.aclweb.org/anthology/W16-5615.pdf  (paper duro y fullNP grammar en el apÃ©ndice del paper) 
                          is_regex = TRUE, 
                          #ngram_max. Por defecto es 8. It is an integer indicating to allow phrases to be found up to ngram maximum number of terms following each other. Only used if is_regex is set to TRUE.
                          #sep = " ". Character indicating how to collapse the phrase of terms which are found. Defaults to using a space.
                          detailed = TRUE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE.
                                          #With TRUE you get keyword, ngran, pattern, start, end
                                          #With FALSE you get keyword, ngram, freq, key
                         )
```



```{r}
# library(dplyr)
# library(plyr)
# 
# cleanStats <- subset(stats2, select = c(keyword, pattern, ngram))
# #Así, podemos obtener la frecuencia de aparicion de un termino específico
# frequency <- ddply(cleanStats, .(keyword, pattern, ngram), nrow)
# 
# #Así, podemos obtener la frecuencia de aparicion de un termino específico
# frequencyOfPOS <- ddply(cleanStats, .(pattern, ngram), nrow)
# 
# #Así, podemos obtener la frecuencia de aparicion de un termino específico
# frequencyOfUPOS <- ddply(x, .(upos), nrow)
# frequencyOfUPOS
```












Otros patrones
<!-- # ```{r} -->
<!-- # x$phrase_tag <- as_phrasemachine(x$upos,  -->
<!-- #                                  type = "upos" #Puede ser tambiÃ©n "penn-treebank" -->
<!-- #                                 )#Convierte los tags de upos a phrasemachine (Handler 2016).  -->
<!-- #  -->
<!-- # stats5  <- keywords_phrases(x = x$phrase_tag,  -->
<!-- #                           term = tolower(x$token),  -->
<!-- #                           #pattern = "(A|N)*N(P+D*(A|N)*N)*", #Default simple noun phrase. See manual. -->
<!-- #                           #pattern = "((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)", #From manual. Noun phrase with coordination conjuction -->
<!-- #                           #pattern =  "((A|N)*N(P+D*(A|N)*N)*P*(M|V)*V(M|V)*|(M|V)*V(M|V)*D*(A|N)*N(P+D*(A|N)*N)*|(M|V)*V(M|V)*(P+D*(A|N)*N)+|(A|N)*N(P+D*(A|N)*N)*P*((M|V)*V(M|V)*D*(A|N)*N(P+D*(A|N)*N)*|(M|V)*V(M|V)*(P+D*(A|N)*N)+))" # Simple verb Phrase -->
<!-- #                           pattern = "(((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)(P(CP)*)*(M(CM)*|V)*V(M(CM)*|V)*(C(M(CM)*|V)*V(M(CM)*|V)*)*|(M(CM)*|V)*V(M(CM)*|V)*(C(M(CM)*|V)*V(M(CM)*|V)*)*(D(CD)*)*((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)|(M(CM)*|V)*V(M(CM)*|V)*(C(M(CM)*|V)*V(M(CM)*|V)*)*((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)+|((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)(P(CP)*)*((M(CM)*|V)*V(M(CM)*|V)*(C(M(CM)*|V)*V(M(CM)*|V)*)*(D(CD)*)*((A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*(C(D(CD)*)*(A(CA)*|N)*N((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)*)*)|(M(CM)*|V)*V(M(CM)*|V)*(C(M(CM)*|V)*V(M(CM)*|V)*)*((P(CP)*)+(D(CD)*)*(A(CA)*|N)*N)+))", # Verb phrase with coordination conjuction -->
<!-- #                           #See also this package to know who/why and how is a full noun phrase. -->
<!-- #                           #MÃ¡s abajo estÃ¡n los ejemplos del manual pdf de esta funciÃ³n. -->
<!-- #                           #AquÃ� se explica el pattern: (1) http://brenocon.com/oconnor_textasdata2016.pdf (slides informales) -->
<!-- #                           #                            (2) https://www.aclweb.org/anthology/W16-5615.pdf  (paper duro y fullNP grammar en el apÃ©ndice del paper)  -->
<!-- #                           is_regex = TRUE,  -->
<!-- #                           #ngram_max. Por defecto es 8. It is an integer indicating to allow phrases to be found up to ngram maximum number of terms following each other. Only used if is_regex is set to TRUE. -->
<!-- #                           #sep = " ". Character indicating how to collapse the phrase of terms which are found. Defaults to using a space. -->
<!-- #                           detailed = TRUE #logical indicating to return the exact positions where the phrase was found (set to TRUE) or just how many times each phrase is occurring (set to FALSE). Defaults to TRUE. -->
<!-- #                                           #With TRUE you get keyword, ngran, pattern, start, end -->
<!-- #                                           #With FALSE you get keyword, ngram, freq, key -->
<!-- #                          ) -->
<!-- # ``` -->

# ```{r}
# # saveRDS(stats, file = "legalTerminology.rds")
# # 
# # saveRDS(t2, file = "t2legal.rds")
# # 
# # stats <- readRDS(file = "legalTerminology.rds")
# ```

