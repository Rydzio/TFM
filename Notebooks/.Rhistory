sum(summ$Sentences)
sum(summ$Tokens)
#Puedo sacar los textos
tDocs <- texts(quancorpusDocs) #No tarda nada.
#Un vector nombrado (cada elemento tiene el nombre del doc).
#Cada elemento es una cadena con el texto del doc.
#Con este proceso limpiamos bien los documentos de caracteres extraños producidos por un error de lectura.
tDocs2 <- str_replace_all(tDocs, c("\001" = "",
"\002" = "",
"\003" = "",
"\004" = "",
"\005" = "",
"\006" = "",
"\f" = ""
)
)
#Debemos volver a establecer los nombres de los documentos, al limpiar los textos se pierden.
attr(tDocs2, 'names') <- attr(tDocs, 'names')
toc()
library(udpipe)
model <- udpipe_download_model(language = "spanish")
path <- model$file_model
#path <- "/Notebooks/spanish-gsd-ud-2.4-190531.udpipe"
tic()
x <- udpipe(tDocs2, path, parallel.cores = hilos)
toc()
library(dplyr)
x$phrase_tag <- as_phrasemachine(x$upos,
type = "upos" #Puede ser tambiÃ©n "penn-treebank"
)#Convierte los tags de upos a phrasemachine (Handler 2016).
tic()
statsPOS2 <- data.frame()
statsPOSSplit <- data.frame()
split(x, x$doc_id) -> xSplit
for (doc_id in xSplit) {
statstTemp <- keywords_phrases(x = doc_id$phrase_tag,
term = tolower(doc_id$token),
pattern = "N(A|N)*(PD*N(A|N)*)*",
is_regex = TRUE,
detailed = FALSE
)
cbind(rep(doc_id$doc_id[1], nrow(statstTemp)), statstTemp) ->> statsPOS2
colnames(statsPOS2)[1] <- "doc_id"
rbind(statsPOS2, statsPOSSplit) ->> statsPOSSplit
}
toc()
statsPOSSplit
statsPOSSplitcopia <- statsPOSSplit
statsPOSSplitcopia2 <- statsPOSSplitcopia
probando <- strsplit(statsPOSSplit$keyword, split = " ")
data.frame(splited = unlist(probando)) -> probando
table(probando) -> tabla
tabla <- data.frame(tabla)
tic()
score = c()
pb = txtProgressBar(min = 0, max = nrow(statsPOSSplit), initial = 0)
for (keyIndex in 1:nrow(statsPOSSplit)) {
if(statsPOSSplit[keyIndex, "ngram"] == 1){
score <- append(score, 0)
} else {
keySplt <- strsplit(statsPOSSplit[keyIndex, "keyword"], " ")
keyDegree <<- statsPOSSplit[keyIndex, "ngram"] - 1
tempScore <- c()
for(word in keySplt){
tempScore <- append(tempScore, keyDegree / tabla[tabla$probando %in% word, ]$Freq)
}
score <- append(score, sum(tempScore))
}
setTxtProgressBar(pb,keyIndex)
}
toc()
cbind(statsPOSSplit, score) -> statsPOSRAKEScore
colnames(statsPOSRAKEScore)[5] <- "RAKE"
statsPOSRAKEScore
probando <- strsplit(statsPOSSplit$keyword, split = " ")
data.frame(splited = unlist(probando)) -> probando
table(probando) -> tabla
tabla <- data.frame(tabla)
tic()
score2 = c()
fprueba = function(x){
if(as.integer(x[3]) == 1){
0
} else {
keySplt <- strsplit(x[2], " ")
keyDegree <<- as.integer(x[3]) - 1
tempScore <- c()
for(word in keySplt){
tempScore <- append(tempScore, keyDegree / tabla[tabla$probando %in% word, ]$Freq)
}
sum(tempScore)
}
}
score2 <- apply(statsPOSSplit, 1, fprueba)
toc()
cbind(statsPOSRAKEScore, score2) -> statsPOSRAKEScore
colnames(statsPOSRAKEScore)[6] <- "RAKE2"
statsPOSRAKEScore <- statsPOSRAKEScore[order(-statsPOSRAKEScore$RAKE),]
statsPOSRAKEScore
library(readtext)
library(tictoc)
library(doParallel)
hilos = detectCores()
#Ruta de trabajo
setwd("~/TFM")
ruta = "/doc"
#ruta = "/legal"
#ruta = "~/InnoSpace/data/corpus_data/Airbus/raw/documents/AMM A310 Jun 15/"
#Leer un corpus
tic()
docs <- readtext(paste0(getwd(),ruta, "*"), #Leo todo lo que tenga ese path
#docvarsfrom = "filenames",
#docvarnames = c("document", "language"),
#dvsep = "_",
#encoding = "UTF-8-BOM", #"ISO-8859-1", #Casi mejor no pongo nada porque no sÃ© el encoding
verbosity = 3)
toc()
print("Se han leido los documentos del corpus con éxito")
library(quanteda)
library(stringr)
tic()
# create quanteda corpus
quanteda_options(threads = hilos)
quancorpusDocs <- corpus(docs)
#Obtenemos un resumen del corpus que hemops creado
#summ <- summary(quancorpusDocs,    #Esto tarda unos segundos. Types es el num de tokens Únicos.
# n = nrow(docs))    #Por defecto son 100
#sum(summ$Sentences)
#sum(summ$Tokens)
#Puedo sacar los textos
tDocs <- texts(quancorpusDocs) #No tarda nada.
#Un vector nombrado (cada elemento tiene el nombre del doc).
#Cada elemento es una cadena con el texto del doc.
#Con este proceso limpiamos bien los documentos de caracteres extraños producidos por un error de lectura.
tDocs2 <- str_replace_all(tDocs, c("\001" = "",
"\002" = "",
"\003" = "",
"\004" = "",
"\005" = "",
"\006" = "",
"\f" = ""
)
)
#Debemos volver a establecer los nombres de los documentos, al limpiar los textos se pierden.
attr(tDocs2, 'names') <- attr(tDocs, 'names')
toc()
library(udpipe)
model <- udpipe_download_model(language = "spanish")
path <- model$file_model
#path <- "/Notebooks/spanish-gsd-ud-2.4-190531.udpipe"
tic()
x <- udpipe(tDocs2, path, parallel.cores = hilos)
toc()
library(dplyr)
x$phrase_tag <- as_phrasemachine(x$upos,
type = "upos" #Puede ser tambiÃ©n "penn-treebank"
)#Convierte los tags de upos a phrasemachine (Handler 2016).
tic()
statsPOS2 <- data.frame()
statsPOSSplit <- data.frame()
split(x, x$doc_id) -> xSplit
for (doc_id in xSplit) {
statstTemp <- keywords_phrases(x = doc_id$phrase_tag,
term = tolower(doc_id$token),
pattern = "N(A|N)*(PD*N(A|N)*)*",
is_regex = TRUE,
detailed = FALSE
)
cbind(rep(doc_id$doc_id[1], nrow(statstTemp)), statstTemp) ->> statsPOS2
colnames(statsPOS2)[1] <- "doc_id"
rbind(statsPOS2, statsPOSSplit) ->> statsPOSSplit
}
toc()
statsPOSSplit
statsPOSSplitcopia <- statsPOSSplit
statsPOSSplitcopia2 <- statsPOSSplitcopia
probando <- strsplit(statsPOSSplit$keyword, split = " ")
data.frame(splited = unlist(probando)) -> probando
table(probando) -> tabla
tabla <- data.frame(tabla)
tic()
score = c()
pb = txtProgressBar(min = 0, max = nrow(statsPOSSplit), initial = 0)
for (keyIndex in 1:nrow(statsPOSSplit)) {
if(statsPOSSplit[keyIndex, "ngram"] == 1){
score <- append(score, 0)
} else {
keySplt <- strsplit(statsPOSSplit[keyIndex, "keyword"], " ")
keyDegree <<- statsPOSSplit[keyIndex, "ngram"] - 1
tempScore <- c()
for(word in keySplt){
tempScore <- append(tempScore, keyDegree / tabla[tabla$probando %in% word, ]$Freq)
}
score <- append(score, sum(tempScore))
}
setTxtProgressBar(pb,keyIndex)
}
toc()
cbind(statsPOSSplit, score) -> statsPOSRAKEScore
colnames(statsPOSRAKEScore)[5] <- "RAKE"
statsPOSRAKEScore
probando <- strsplit(statsPOSSplit$keyword, split = " ")
data.frame(splited = unlist(probando)) -> probando
table(probando) -> tabla
tabla <- data.frame(tabla)
tic()
score2 = c()
fprueba = function(x){
if(as.integer(x[3]) == 1){
0
} else {
keySplt <- strsplit(x[2], " ")
keyDegree <<- as.integer(x[3]) - 1
tempScore <- c()
for(word in keySplt){
tempScore <- append(tempScore, keyDegree / tabla[tabla$probando %in% word, ]$Freq)
}
sum(tempScore)
}
}
score2 <- apply(statsPOSSplit, 1, fprueba)
toc()
cbind(statsPOSRAKEScore, score2) -> statsPOSRAKEScore
colnames(statsPOSRAKEScore)[6] <- "RAKE2"
statsPOSRAKEScore
#Agrupamos la terminologia en funcion del documento, generando una terminología completa del corpus entero.
stats <- select(statsPOSRAKEScore, -c(doc_id))
stats <- aggregate(list(Frecuencia=stats$freq, RAKE1=stats$RAKE, RAKE2=stats$RAKE2), by=list(keyword=stats$keyword, ngram=stats$ngram), FUN=sum)
stats
pb = txtProgressBar(min = 0, max = nrow(stats), initial = 0)
cValue <- c()
tic()
for (keyIndex in 1:nrow(stats)) {
#Extraemos el termino candidato
candidate <- stats[keyIndex, "keyword"]
#Extraemos la frecuencia del candidato en el corpùs
freqCandidate <- stats[keyIndex, "Frecuencia"]
#Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
#Numero de coincidencias
ncoincidencias <- nrow(coincidencias)
if(ncoincidencias == 1){
#El candidato no esta contenido en otro termino
#Calculamos c-value
res <- log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#Almacenamos el resultado
append(cValue, res) ->> cValue
} else {
sumatorio <- sum(coincidencias$freq)
res <- log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#Almacenamos el resultado
append(cValue, res) ->> cValue
}
setTxtProgressBar(pb,keyIndex)
}
toc()
print("fin")
cbind(stats, cValue) -> statsPOSCVALUE
colnames(statsPOSCVALUE)[6] <- "cvalue"
statsPOSCVALUE
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
print(keyIndex)
# #Extraemos el termino candidato
# candidate <- stats[keyIndex, "keyword"]
# #Extraemos la frecuencia del candidato en el corpùs
# freqCandidate <- stats[keyIndex, "Frecuencia"]
#
# #Buscamos terminos que contengan a nuestro candidato.
# coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
#
# #Numero de coincidencias
# ncoincidencias <- nrow(coincidencias)
# if(ncoincidencias == 1){
#   #El candidato no esta contenido en otro termino
#   #Calculamos c-value
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#   #Almacenamos el resultado
#
# } else {
#   sumatorio <- sum(coincidencias$freq)
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#   #Almacenamos el resultado
# }
# setTxtProgressBar(pb,keyIndex)
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
print(candidate)
print(freqCandidate)
# #Buscamos terminos que contengan a nuestro candidato.
# coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
#
# #Numero de coincidencias
# ncoincidencias <- nrow(coincidencias)
# if(ncoincidencias == 1){
#   #El candidato no esta contenido en otro termino
#   #Calculamos c-value
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#   #Almacenamos el resultado
#
# } else {
#   sumatorio <- sum(coincidencias$freq)
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#   #Almacenamos el resultado
# }
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
# coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
#
# #Numero de coincidencias
# ncoincidencias <- nrow(coincidencias)
# if(ncoincidencias == 1){
#   #El candidato no esta contenido en otro termino
#   #Calculamos c-value
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#   #Almacenamos el resultado
#
# } else {
#   sumatorio <- sum(coincidencias$freq)
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#   #Almacenamos el resultado
# }
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
print(coincidencias)
#
# #Numero de coincidencias
# ncoincidencias <- nrow(coincidencias)
# if(ncoincidencias == 1){
#   #El candidato no esta contenido en otro termino
#   #Calculamos c-value
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#   #Almacenamos el resultado
#
# } else {
#   sumatorio <- sum(coincidencias$freq)
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#   #Almacenamos el resultado
# }
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
# #Numero de coincidencias
ncoincidencias <- nrow(coincidencias)ç
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
# #Numero de coincidencias
ncoincidencias <- nrow(coincidencias)
print(ncoincidencias)
# if(ncoincidencias == 1){
#   #El candidato no esta contenido en otro termino
#   #Calculamos c-value
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate
#   #Almacenamos el resultado
#
# } else {
#   sumatorio <- sum(coincidencias$freq)
#   log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio
#   #Almacenamos el resultado
# }
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
# #Numero de coincidencias
ncoincidencias <- nrow(coincidencias)
if(ncoincidencias == 1){
#El candidato no esta contenido en otro termino
#Calculamos c-value
log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate -> res
print(res)
res
#Almacenamos el resultado
} else {
sumatorio <- sum(coincidencias$freq)
log2(length(strsplit(candidate, " ")[[1]])) * freqCandidate - (1 / ncoincidencias) * sumatorio -> res
print(res)
res
#Almacenamos el resultado
}
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
# #Numero de coincidencias
ncoincidencias <- nrow(coincidencias)
if(ncoincidencias == 1){
#El candidato no esta contenido en otro termino
#Calculamos c-value
log2(length(strsplit(candidate, " ")[[1]])) * as.integer(freqCandidate) -> res
print(res)
res
#Almacenamos el resultado
} else {
sumatorio <- sum(coincidencias$freq)
log2(length(strsplit(candidate, " ")[[1]])) * as.integer(freqCandidate) - (1 / ncoincidencias) * sumatorio -> res
print(res)
res
#Almacenamos el resultado
}
}
cValue2 = apply(stats, 1, fcvalue)
cValue2 <- c()
tic()
fcvalue = function(keyIndex) {
#Extraemos el termino candidato
#candidate <- stats[keyIndex, "keyword"]
candidate <- keyIndex[1]
#Extraemos la frecuencia del candidato en el corpùs
#freqCandidate <- stats[keyIndex, "Frecuencia"]
freqCandidate <- keyIndex[3]
#print(class(candidate))
# #Buscamos terminos que contengan a nuestro candidato.
coincidencias <- stats[grepl(candidate ,stats$keyword, fixed = TRUE), ]
# #Numero de coincidencias
ncoincidencias <- nrow(coincidencias)
if(ncoincidencias == 1){
#El candidato no esta contenido en otro termino
#Calculamos c-value
log2(length(strsplit(candidate, " ")[[1]])) * as.integer(freqCandidate) -> res
#print(res)
res
#Almacenamos el resultado
} else {
sumatorio <- sum(coincidencias$freq)
log2(length(strsplit(candidate, " ")[[1]])) * as.integer(freqCandidate) - (1 / ncoincidencias) * sumatorio -> res
#print(res)
res
#Almacenamos el resultado
}
}
cValue2 = apply(stats, 1, fcvalue)
toc()
print("fin")
cbind(statsPOSCVALUE, cValue2) -> statsPOSCVALUE
colnames(statsPOSCVALUE)[7] <- "cvalue"
statsPOSCVALUE
View(statsPOSCVALUE)
